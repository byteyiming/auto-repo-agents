#!/usr/bin/env python3
"""
å¿«é€Ÿæµ‹è¯• Ollama æœ¬åœ°è¿æ¥
"""
import os
import sys

# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ['LLM_PROVIDER'] = 'ollama'
os.environ['OLLAMA_DEFAULT_MODEL'] = 'mistral'  # ä½¿ç”¨ä½ å·²å®‰è£…çš„æ¨¡å‹
os.environ['OLLAMA_MAX_TOKENS'] = '8192'

try:
    from src.llm.ollama_provider import OllamaProvider
    
    print("ğŸ” æµ‹è¯• Ollama è¿æ¥...")
    provider = OllamaProvider()
    
    # æµ‹è¯•è¿æ¥
    if provider.validate_config():
        print("âœ… Ollama æœåŠ¡è¿æ¥æˆåŠŸï¼")
        print(f"   æœåŠ¡åœ°å€: {provider.base_url}")
        print(f"   é»˜è®¤æ¨¡å‹: {provider.default_model_name}")
        
        # æµ‹è¯•ç”Ÿæˆ
        print("\nğŸ§ª æµ‹è¯•æ–‡æœ¬ç”Ÿæˆ...")
        test_prompt = "ç”¨ä¸€å¥è¯ä»‹ç» Python ç¼–ç¨‹è¯­è¨€"
        result = provider.generate(test_prompt, temperature=0.7)
        print(f"âœ… ç”ŸæˆæˆåŠŸï¼")
        print(f"   æç¤º: {test_prompt}")
        print(f"   å›å¤: {result[:100]}...")
        
        print("\nâœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Ollama å¯ä»¥æ­£å¸¸ä½¿ç”¨ã€‚")
    else:
        print("âŒ Ollama æœåŠ¡è¿æ¥å¤±è´¥")
        print("   è¯·ç¡®ä¿ï¼š")
        print("   1. Ollama æœåŠ¡æ­£åœ¨è¿è¡Œ: ollama serve")
        print("   2. æ¨¡å‹å·²ä¸‹è½½: ollama pull dolphin3")
        print("   3. æœåŠ¡åœ°å€æ­£ç¡®: http://localhost:11434")
        sys.exit(1)
        
except ImportError as e:
    print(f"âŒ å¯¼å…¥é”™è¯¯: {e}")
    print("   è¯·ç¡®ä¿å·²å®‰è£…é¡¹ç›®ä¾èµ–: pip install -e .")
    sys.exit(1)
except Exception as e:
    print(f"âŒ é”™è¯¯: {e}")
    sys.exit(1)
